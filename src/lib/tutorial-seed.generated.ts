/* eslint-disable */
// Auto-generated by scripts/generate-tutorial-seed.mjs
// Do not edit manually.

type SeedDocument = {
  key: string;
  contentType: string;
  content: string;
};

export const SEEDED_DOCUMENTS: SeedDocument[] = [
  {
    "key": "Getting Started.md",
    "contentType": "text/markdown; charset=utf-8",
    "content": "# Getting Started\n\nYou have a full Linux container in your browser. An AI agent is loaded and waiting in Tab 1. Five more terminals behind it. Your files sync every 60 seconds to cloud storage that outlives every container you'll ever start. Here's what to do with all of that.\n\n---\n\n## The 30-Second Version\n\n1. **Create a session** from the Dashboard -- pick your agent\n2. **Open it** -- Tab 1 is ready, no loading screen, no \"please wait\"\n3. **Clone a repo** in Tab 4 and point your agent at it\n4. **Work** -- the agent has full root access. It can read, write, build, test, and deploy. Let it cook.\n5. **Stop when you're done** -- final sync happens automatically. The container dies. Your files don't.\n\nThat's it. The rest of this page is for the curious.\n\n---\n\n## What's in Each Tab\n\n| Tab | What | Why it's there |\n|-----|------|---------------|\n| 1 | Your AI agent | Pre-warmed during container startup. Already loaded when you click Open. |\n| 2 | htop | Because \"why is this slow\" is always the first question. |\n| 3 | yazi | Terminal file manager. Like `ls` and `cd` had a baby that actually cares about UX. |\n| 4-6 | bash | Three blank canvases. Run servers, tests, scripts, or `cowsay`. I don't judge. |\n\nTabs 2-6 are draggable. Rearrange them however you want -- your order is saved.\n\n**Tiling mode** -- button in the top-right corner. View 2-4 terminals side by side instead of switching tabs. Agent in one pane, dev server in another, htop keeping an eye on things in the third. Once you tile, you don't go back.\n\n---\n\n## Your Files Persist (You Don't Have to Think About It)\n\nA daemon syncs your home directory to Cloudflare R2 every 60 seconds. When you stop a session, a final sync runs before the container self-destructs. When you start a new one, everything is restored. Even if a session dies before you remember to `git push`, R2 sync has got your back. Sync conflicts will happen -- Codeflare cleans them up automatically on the next cycle. Don't worry about it.\n\nWhat carries over: `.bashrc`, `.gitconfig`, `~/.claude/` (API keys, settings, project memory), and anything else in your home directory. Set your API key once. It's there forever.\n\nThe **R2 File Browser** on the Dashboard lets you browse, upload, download, and delete synced files between sessions -- without starting a container.\n\n---\n\n## API Keys\n\nYour agent needs a key. Set it once, sync takes care of the rest.\n\n| Agent | First-Time Setup |\n|-------|-----------------|\n| Claude Unleashed | `echo 'export ANTHROPIC_API_KEY=sk-ant-...' >> ~/.bashrc` |\n| Codex | `echo 'export OPENAI_API_KEY=sk-...' >> ~/.bashrc` |\n| Gemini | `echo 'export GEMINI_API_KEY=...' >> ~/.bashrc` |\n\nNext session, the key is already there. Magic. (It's rclone, but magic sounds better.)\n\n---\n\n## What Now\n\nThree paths. Pick whichever matches your personality:\n\n1. **Check the Examples** -- copy-paste prompts from beginner to expert. Your agent does the work, you take the credit.\n2. **Read the Documentation** -- architecture, sync internals, terminal features, troubleshooting. It's thorough.\n3. **Just wing it** -- create a session, clone something, and tell your agent what you want. Worst case, you lose an ephemeral container. Best case, you ship before lunch.\n\nExamples and docs are in the `tutorials/` folder, or browse them in the R2 File Browser on the Dashboard.\n"
  },
  {
    "key": "Assets/alert-circle.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M13,13H11V7H13M13,17H11V15H13M12,2A10,10 0 0,0 2,12A10,10 0 0,0 12,22A10,10 0 0,0 22,12A10,10 0 0,0 12,2Z\" fill=\"currentColor\"/>\n</svg>"
  },
  {
    "key": "Assets/arrow-left.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M20,11V13H8L13.5,18.5L12.08,19.92L4.16,12L12.08,4.08L13.5,5.5L8,11H20Z\" fill=\"currentColor\"/>\n</svg>"
  },
  {
    "key": "Assets/arrow-right.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M4,11V13H16L10.5,18.5L11.92,19.92L19.84,12L11.92,4.08L10.5,5.5L16,11H4Z\" fill=\"currentColor\"/>\n</svg>"
  },
  {
    "key": "Assets/check.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z\" fill=\"currentColor\"/>\n</svg>\n"
  },
  {
    "key": "Assets/chevron-down.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M7.41,8.58L12,13.17L16.59,8.58L18,10L12,16L6,10L7.41,8.58Z\" fill=\"currentColor\"/>\n</svg>"
  },
  {
    "key": "Assets/chevron-up.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M7.41,15.41L12,10.83L16.59,15.41L18,14L12,8L6,14L7.41,15.41Z\" fill=\"currentColor\"/>\n</svg>"
  },
  {
    "key": "Assets/close.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M19,6.41L17.59,5L12,10.59L6.41,5L5,6.41L10.59,12L5,17.59L6.41,19L12,13.41L17.59,19L19,17.59L13.41,12L19,6.41Z\" fill=\"currentColor\"/>\n</svg>\n"
  },
  {
    "key": "Assets/cloud.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M6.5 20Q4.22 20 2.61 18.43 1 16.85 1 14.58 1 12.63 2.17 11.1 3.35 9.57 5.25 9.15 5.88 6.85 7.75 5.43 9.63 4 12 4 14.93 4 16.96 6.04 19 8.07 19 11 20.73 11.2 21.86 12.5 23 13.78 23 15.5 23 17.38 21.69 18.69 20.38 20 18.5 20Z\" fill=\"currentColor\"/>\n</svg>\n"
  },
  {
    "key": "Assets/code-tags.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M14.6,16.6L19.2,12L14.6,7.4L16,6L22,12L16,18L14.6,16.6M9.4,16.6L4.8,12L9.4,7.4L8,6L2,12L8,18L9.4,16.6Z\" fill=\"currentColor\"/>\n</svg>\n"
  },
  {
    "key": "Assets/cog.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M12,15.5A3.5,3.5 0 0,1 8.5,12A3.5,3.5 0 0,1 12,8.5A3.5,3.5 0 0,1 15.5,12A3.5,3.5 0 0,1 12,15.5M19.43,12.97C19.47,12.65 19.5,12.33 19.5,12C19.5,11.67 19.47,11.34 19.43,11L21.54,9.37C21.73,9.22 21.78,8.95 21.66,8.73L19.66,5.27C19.54,5.05 19.27,4.96 19.05,5.05L16.56,6.05C16.04,5.66 15.5,5.32 14.87,5.07L14.5,2.42C14.46,2.18 14.25,2 14,2H10C9.75,2 9.54,2.18 9.5,2.42L9.13,5.07C8.5,5.32 7.96,5.66 7.44,6.05L4.95,5.05C4.73,4.96 4.46,5.05 4.34,5.27L2.34,8.73C2.21,8.95 2.27,9.22 2.46,9.37L4.57,11C4.53,11.34 4.5,11.67 4.5,12C4.5,12.33 4.53,12.65 4.57,12.97L2.46,14.63C2.27,14.78 2.21,15.05 2.34,15.27L4.34,18.73C4.46,18.95 4.73,19.03 4.95,18.95L7.44,17.94C7.96,18.34 8.5,18.68 9.13,18.93L9.5,21.58C9.54,21.82 9.75,22 10,22H14C14.25,22 14.46,21.82 14.5,21.58L14.87,18.93C15.5,18.67 16.04,18.34 16.56,17.94L19.05,18.95C19.27,19.03 19.54,18.95 19.66,18.73L21.66,15.27C21.78,15.05 21.73,14.78 21.54,14.63L19.43,12.97Z\" fill=\"currentColor\"/>\n</svg>\n"
  },
  {
    "key": "Assets/console.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M20,19V7H4V19H20M20,3A2,2 0 0,1 22,5V19A2,2 0 0,1 20,21H4A2,2 0 0,1 2,19V5C2,3.89 2.9,3 4,3H20M13,17V15H18V17H13M9.58,13L5.57,9H8.4L11.7,12.3C12.09,12.69 12.09,13.33 11.7,13.72L8.42,17H5.59L9.58,13Z\" fill=\"currentColor\"/>\n</svg>\n"
  },
  {
    "key": "Assets/database.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M12,3C7.58,3 4,4.79 4,7C4,9.21 7.58,11 12,11C16.42,11 20,9.21 20,7C20,4.79 16.42,3 12,3M4,9V12C4,14.21 7.58,16 12,16C16.42,16 20,14.21 20,12V9C20,11.21 16.42,13 12,13C7.58,13 4,11.21 4,9M4,14V17C4,19.21 7.58,21 12,21C16.42,21 20,19.21 20,17V14C20,16.21 16.42,18 12,18C7.58,18 4,16.21 4,14Z\" fill=\"currentColor\"/>\n</svg>\n"
  },
  {
    "key": "Assets/delete.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M19,4H15.5L14.5,3H9.5L8.5,4H5V6H19M6,19A2,2 0 0,0 8,21H16A2,2 0 0,0 18,19V7H6V19Z\" fill=\"currentColor\"/>\n</svg>"
  },
  {
    "key": "Assets/download.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M5,20H19V18H5M19,9H15V3H9V9H5L12,16L19,9Z\" fill=\"currentColor\"/>\n</svg>\n"
  },
  {
    "key": "Assets/file.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M13,9V3.5L18.5,9M6,2C4.89,2 4,2.89 4,4V20A2,2 0 0,0 6,22H18A2,2 0 0,0 20,20V8L14,2H6Z\" fill=\"currentColor\"/>\n</svg>\n"
  },
  {
    "key": "Assets/folder-open.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M19,20H4C2.89,20 2,19.1 2,18V6C2,4.89 2.89,4 4,4H10L12,6H19A2,2 0 0,1 21,8H21L4,8V18L6.14,10H23.21L20.93,18.5C20.7,19.37 19.92,20 19,20Z\" fill=\"currentColor\"/>\n</svg>"
  },
  {
    "key": "Assets/folder.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M10,4H4C2.89,4 2,4.89 2,6V18A2,2 0 0,0 4,20H20A2,2 0 0,0 22,18V8C22,6.89 21.1,6 20,6H12L10,4Z\" fill=\"currentColor\"/>\n</svg>\n"
  },
  {
    "key": "Assets/git.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M2.6,10.59L8.38,4.8L10.07,6.5C9.83,7.35 10.22,8.28 11,8.73V14.27C10.4,14.61 10,15.26 10,16A2,2 0 0,0 12,18A2,2 0 0,0 14,16C14,15.26 13.6,14.61 13,14.27V9.41L15.07,11.5C15,11.65 15,11.82 15,12A2,2 0 0,0 17,14A2,2 0 0,0 19,12A2,2 0 0,0 17,10C16.82,10 16.65,10 16.5,10.07L13.93,7.5C14.19,6.57 13.71,5.55 12.78,5.16C12.35,5 11.9,4.96 11.5,5.07L9.8,3.38L10.59,2.6C11.37,1.81 12.63,1.81 13.41,2.6L21.4,10.59C22.19,11.37 22.19,12.63 21.4,13.41L13.41,21.4C12.63,22.19 11.37,22.19 10.59,21.4L2.6,13.41C1.81,12.63 1.81,11.37 2.6,10.59Z\" fill=\"currentColor\"/>\n</svg>"
  },
  {
    "key": "Assets/github.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M12,2A10,10 0 0,0 2,12C2,16.42 4.87,20.17 8.84,21.5C9.34,21.58 9.5,21.27 9.5,21C9.5,20.77 9.5,20.14 9.5,19.31C6.73,19.91 6.14,17.97 6.14,17.97C5.68,16.81 5.03,16.5 5.03,16.5C4.12,15.88 5.1,15.9 5.1,15.9C6.1,15.97 6.63,16.93 6.63,16.93C7.5,18.45 8.97,18 9.54,17.76C9.63,17.11 9.89,16.67 10.17,16.42C7.95,16.17 5.62,15.31 5.62,11.5C5.62,10.39 6,9.5 6.65,8.79C6.55,8.54 6.2,7.5 6.75,6.15C6.75,6.15 7.59,5.88 9.5,7.17C10.29,6.95 11.15,6.84 12,6.84C12.85,6.84 13.71,6.95 14.5,7.17C16.41,5.88 17.25,6.15 17.25,6.15C17.8,7.5 17.45,8.54 17.35,8.79C18,9.5 18.38,10.39 18.38,11.5C18.38,15.32 16.04,16.16 13.81,16.41C14.17,16.72 14.5,17.33 14.5,18.26C14.5,19.6 14.5,20.68 14.5,21C14.5,21.27 14.66,21.59 15.17,21.5C19.14,20.16 22,16.42 22,12A10,10 0 0,0 12,2Z\" fill=\"currentColor\"/>\n</svg>"
  },
  {
    "key": "Assets/help-circle.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M15.07,11.25L14.17,12.17C13.45,12.89 13,13.5 13,15H11V14.5C11,13.39 11.45,12.39 12.17,11.67L13.41,10.41C13.78,10.05 14,9.55 14,9C14,7.89 13.1,7 12,7A2,2 0 0,0 10,9H8A4,4 0 0,1 12,5A4,4 0 0,1 16,9C16,9.88 15.64,10.67 15.07,11.25M13,19H11V17H13M12,2A10,10 0 0,0 2,12A10,10 0 0,0 12,22A10,10 0 0,0 22,12C22,6.47 17.5,2 12,2Z\" fill=\"currentColor\"/>\n</svg>"
  },
  {
    "key": "Assets/home.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M10,20V14H14V20H19V12H22L12,3L2,12H5V20H10Z\" fill=\"currentColor\"/>\n</svg>\n"
  },
  {
    "key": "Assets/information.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M13,9H11V7H13M13,17H11V11H13M12,2A10,10 0 0,0 2,12A10,10 0 0,0 12,22A10,10 0 0,0 22,12A10,10 0 0,0 12,2Z\" fill=\"currentColor\"/>\n</svg>"
  },
  {
    "key": "Assets/key.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M7 14C5.9 14 5 13.1 5 12S5.9 10 7 10 9 10.9 9 12 8.1 14 7 14M12.6 10C11.8 7.7 9.6 6 7 6C3.7 6 1 8.7 1 12S3.7 18 7 18C9.6 18 11.8 16.3 12.6 14H16V18H20V14H23V10H12.6Z\" fill=\"currentColor\"/>\n</svg>\n"
  },
  {
    "key": "Assets/lock.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M12,17A2,2 0 0,0 14,15C14,13.89 13.1,13 12,13A2,2 0 0,0 10,15A2,2 0 0,0 12,17M18,8A2,2 0 0,1 20,10V20A2,2 0 0,1 18,22H6A2,2 0 0,1 4,20V10C4,8.89 4.9,8 6,8H7V6A5,5 0 0,1 12,1A5,5 0 0,1 17,6V8H18M12,3A3,3 0 0,0 9,6V8H15V6A3,3 0 0,0 12,3Z\" fill=\"currentColor\"/>\n</svg>\n"
  },
  {
    "key": "Assets/magnify.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M9.5,3A6.5,6.5 0 0,1 16,9.5C16,11.11 15.41,12.59 14.44,13.73L14.71,14H15.5L20.5,19L19,20.5L14,15.5V14.71L13.73,14.44C12.59,15.41 11.11,16 9.5,16A6.5,6.5 0 0,1 3,9.5A6.5,6.5 0 0,1 9.5,3M9.5,5C7,5 5,7 5,9.5C5,12 7,14 9.5,14C12,14 14,12 14,9.5C14,7 12,5 9.5,5Z\" fill=\"currentColor\"/>\n</svg>\n"
  },
  {
    "key": "Assets/menu.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M3,6H21V8H3V6M3,11H21V13H3V11M3,16H21V18H3V16Z\" fill=\"currentColor\"/>\n</svg>"
  },
  {
    "key": "Assets/pencil.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M20.71,7.04C21.1,6.65 21.1,6 20.71,5.63L18.37,3.29C18,2.9 17.35,2.9 16.96,3.29L15.12,5.12L18.87,8.87M3,17.25V21H6.75L17.81,9.93L14.06,6.18L3,17.25Z\" fill=\"currentColor\"/>\n</svg>\n"
  },
  {
    "key": "Assets/plus.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M19,13H13V19H11V13H5V11H11V5H13V11H19V13Z\" fill=\"currentColor\"/>\n</svg>\n"
  },
  {
    "key": "Assets/refresh.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M17.65,6.35C16.2,4.9 14.21,4 12,4A8,8 0 0,0 4,12A8,8 0 0,0 12,20C15.73,20 18.84,17.45 19.73,14H17.65C16.83,16.33 14.61,18 12,18A6,6 0 0,1 6,12A6,6 0 0,1 12,6C13.66,6 15.14,6.69 16.22,7.78L13,11H20V4L17.65,6.35Z\" fill=\"currentColor\"/>\n</svg>"
  },
  {
    "key": "Assets/upload.svg",
    "contentType": "application/octet-stream",
    "content": "<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\" width=\"24\" height=\"24\">\n  <path d=\"M9,16V10H5L12,3L19,10H15V16H9M5,20V18H19V20H5Z\" fill=\"currentColor\"/>\n</svg>\n"
  },
  {
    "key": "Documentation/Readme.md",
    "contentType": "text/markdown; charset=utf-8",
    "content": "# Codeflare\n\nI set out to prove that fully autonomous AI development actually works when done properly. Gave coding agents a detailed specification, made them follow TDD principles, and let them run unchecked. Somewhere along the way I accidentally built my favorite development environment.\n\nCodeflare is an ephemeral cloud IDE that runs entirely in your browser. Every session spins up an isolated container on Cloudflare, pre-loads your AI agent of choice, and tears itself down when you're done. Your files persist in R2 storage. The containers don't. Nothing touches your local machine.\n\nIt's strongly optimized for mobile -- because the best ideas hit while rewatching your favorite show for the 15th time, and your PC is just too far away.\n\n## The Problem\n\nSetting up a dev environment is tedious. Configuring one for AI-assisted coding is worse -- you need the right CLI tools, API keys, a terminal multiplexer, and enough compute to feel responsive. Want to work from a different machine? Start over. Want to experiment without cluttering your local system? Out of luck.\n\nCodeflare moves the whole thing to the cloud. Open a browser, start a session, and within seconds you have a fully configured workspace. Your files and settings persist across sessions via R2. When you're done, the container is destroyed. When you come back, a new one spins up with your data already synced. Even if a session dies before you `git push`, R2 sync has got your back.\n\n## Supported Agents\n\nCodeflare isn't tied to any single AI provider. Each session lets you choose which agent runs in your primary terminal tab:\n\n| Agent | Description |\n|-------|-------------|\n| [Claude Unleashed](https://github.com/nikolanovoselec/claude-unleashed) | Anthropic's Claude Code, minus the \"please don't run as root\" lectures |\n| Codex | OpenAI's Codex CLI agent |\n| Gemini | Google's Gemini CLI agent |\n| Bash | No AI agent -- a plain terminal for the purists |\n\nAll four are first-class citizens. Pick the one that fits your task, or use Bash if you prefer working without an AI assistant.\n\n## What You Get\n\n- **Browser-native terminal with 6 tabs per session.** Full Linux containers with root access, available in seconds from any browser. No local installation required.\n- **One isolated container per session.** No shared state between sessions. Agents can't escape their sandbox (I checked).\n- **Pre-warmed terminals.** The agent starts loading during container startup. By the time you click Open, it's ready -- not staring at a blank screen wondering if something broke.\n- **Persistent R2 storage with bisync every 60s.** Files, shell config, and credentials survive container teardown. Set your API key once. It's there forever.\n- **Terminal tiling.** View 2-4 terminals side by side. Once you tile, you don't go back.\n- **R2 file browser.** Browse, upload, download, and manage files directly from the dashboard -- without starting a container.\n- **User management.** Email-based allowlists and role-based permissions (admin and user). Invite users or revoke them when they get too creative.\n- **Setup wizard.** First-time deployment walks you through DNS, auth, and storage config. Takes a few minutes, only happens once.\n- **Auto-idle teardown.** Containers shut down after inactivity. You pay for what you use. Nothing when you don't.\n- **Dashboard with live metrics.** CPU, memory, disk, uptime, and sync status at a glance.\n\n## Architecture\n\n```mermaid\nflowchart LR\n    A[Browser] --> B[\"Cloudflare Worker\n    Hono router + SolidJS static UI\"]\n    B --> C[\"Durable Object\n    session lifecycle + hibernation\"]\n    C --> D[\"Cloudflare Container\n    isolated per session, pre-warmed PTY\"]\n    D --> E[\"R2\n    per-user storage, bisync every 60s\"]\n```\n\nEach session maps to a single container. The Worker handles routing and auth. Durable Objects manage session lifecycle. Containers provide the compute. R2 provides storage that outlives every container you'll ever start.\n\nContainers scale to zero when idle (no sessions = no bill). Auth is handled by Cloudflare Access -- no custom login pages, no token management, no OAuth dance.\n\n## Security\n\n- Every session runs in its own container. No shared shells, no cross-session access. Your agent can `rm -rf /` and the only victim is itself.\n- AI agents run with full terminal access *inside* the container -- and can't get out. I gave them root and a sandbox. They got root in a sandbox.\n- Cloudflare Access gates all authenticated surfaces (`/app`, `/api`, `/setup`).\n- API tokens never enter the container. Secrets stay in GitHub and Cloudflare. The agent doesn't know your passwords, and frankly, it doesn't want to.\n- Optional Turnstile bot protection for public-facing onboarding flows.\n\n## Resource Tiers\n\n| Tier | vCPU | Memory | Disk |\n|------|------|--------|------|\n| Low | 0.25 vCPU | 1 GiB RAM | 4 GB |\n| Default | 1 vCPU | 3 GiB RAM | 4 GB |\n| High | 2 vCPU | 6 GiB RAM | 8 GB |\n\nLow tier handles light editing and AI agents fine. Default covers most dev workflows. High is for when your build process has ambitions.\n\n## Cost Estimate\n\nRuns on Cloudflare Containers -- usage-based pricing on the Workers Paid plan ($5/month base). Realistic breakdown for default tier (1 vCPU, 3 GiB RAM), 8 hours/day, 20 days/month, 20% average CPU:\n\n**Total active time:** 8h x 20d = 160 hours = 576,000 seconds\n\n| Resource | Usage | Included Free | Overage | Rate | Cost |\n|----------|-------|---------------|---------|------|------|\n| vCPU | 0.20 x 1 vCPU x 576,000s = 115,200 vCPU-s | 22,500 vCPU-s | 92,700 vCPU-s | $0.000020/vCPU-s | $1.85 |\n| Memory | 3 GiB x 576,000s = 1,728,000 GiB-s | 90,000 GiB-s | 1,638,000 GiB-s | $0.0000025/GiB-s | $4.10 |\n| Disk | 4 GB x 576,000s = 2,304,000 GB-s | 720,000 GB-s | 1,584,000 GB-s | $0.00000007/GB-s | $0.11 |\n| **Workers Paid plan** | | | | | **$5.00** |\n| **Total** | | | | | **~$11/month** |\n\nLow tier at the same usage pattern: ~$6.50/month. If you offload builds to GitHub Actions, low tier is more than enough for editing and running agents.\n\nPricing based on published Cloudflare Containers rates as of early 2026. Check the [Cloudflare Containers pricing page](https://developers.cloudflare.com/containers/pricing/) for current rates.\n\n## Deployment\n\nFork the repo, set your Cloudflare credentials as GitHub secrets, go to `Actions` > `Deploy` > `Run workflow` > Branch: `main` > **Run workflow**. GitHub Actions builds, tests, and deploys. Takes about 2 minutes.\n\nAfter deployment, visit your Worker URL and the setup wizard handles:\n\n1. DNS configuration (CNAME for your custom domain)\n2. Cloudflare Access setup (auth and user allowlist)\n3. R2 credential derivation (automatic, no manual token creation)\n\nThat's it. No Kubernetes. No Terraform. No existential crisis.\n\n## License\n\nPolyForm Noncommercial 1.0.0 -- free for personal use, tinkering, and showing off.\n\nCommercial use, resale, or paid hosted offerings require a separate written license. You know who you are.\n\n## Built By\n\n[Nikola Novoselec](https://github.com/nikolanovoselec)\n"
  },
  {
    "key": "Documentation/Toolchain.md",
    "contentType": "text/markdown; charset=utf-8",
    "content": "# Toolchain: GitHub to Cloudflare Workers\n\nHow to set up a deployment pipeline for your Cloudflare Workers projects. Every step shows two paths: ask your AI coding agent in Tab 1, or do it manually from a terminal tab.\n\n---\n\n## Overview\n\n```\nCodeflare terminal\n  |\n  git push\n  |\nGitHub repository\n  |\nGitHub Actions (on push to main)\n  |\nwrangler deploy\n  |\nCloudflare Workers (live)\n```\n\n---\n\n## Step 1: Create a Cloudflare API Token\n\nYou need a token that lets GitHub Actions deploy Workers on your behalf.\n\n1. Go to https://dash.cloudflare.com/profile/api-tokens\n2. Click **Create Token**\n3. Use the **Edit Cloudflare Workers** template (this grants the right permissions)\n4. Under **Account Resources**, select the account you want to deploy to\n5. Under **Zone Resources**, select **All zones** (or a specific zone if you prefer)\n6. Click **Continue to summary**, then **Create Token**\n7. **Copy the token** -- you will not see it again\n\nYou also need your **Account ID**:\n1. Go to any zone in the Cloudflare dashboard\n2. On the right sidebar, find **Account ID**\n3. Copy it\n\n---\n\n## Step 2: Set Up a GitHub Repository\n\n### Ask your agent:\n\n```\nCreate a new GitHub repo called \"my-project\", clone it into ~/workspace, and set it up with a .gitignore for Node.js\n```\n\n### Or do it yourself:\n\n**Option A -- Create on GitHub first (easiest for beginners):**\n\n1. Go to https://github.com/new\n2. Name your repository, choose public or private, click **Create repository**\n3. From a Codeflare terminal (Tab 4, 5, or 6):\n\n```bash\ncd ~/workspace\ngit clone https://github.com/your-username/your-project.git\ncd your-project\n```\n\n**Option B -- Create from the terminal (if you already have code):**\n\n```bash\ncd ~/workspace/your-project\ngit init\ngit add .\ngit commit -m \"Initial commit\"\ngh repo create your-project --public --source=. --remote=origin --push\n```\n\nThe `gh` CLI is pre-installed in every Codeflare session.\n\n---\n\n## Step 3: Add Secrets to GitHub\n\nYour API token must never be committed to code or pasted into an AI agent. The safest method is to add secrets directly in the GitHub UI -- the token never touches your terminal or any agent context.\n\n**From the GitHub UI (recommended):**\n\n1. Go to your repo on GitHub\n2. Settings > Secrets and variables > Actions\n3. Click **New repository secret**\n4. Add `CLOUDFLARE_API_TOKEN` with your token value\n5. Add `CLOUDFLARE_ACCOUNT_ID` with your account ID\n\n**From the terminal (alternative):**\n\n```bash\ngh secret set CLOUDFLARE_API_TOKEN --body \"your-token-here\"\ngh secret set CLOUDFLARE_ACCOUNT_ID --body \"your-account-id-here\"\n```\n\n---\n\n## Step 4: Create the GitHub Actions Workflow\n\n### Ask your agent:\n\n```\nCreate a GitHub Actions workflow that deploys this project to Cloudflare Workers on every push to main. It should install dependencies, run tests, and deploy using the wrangler-action. Use CLOUDFLARE_API_TOKEN and CLOUDFLARE_ACCOUNT_ID secrets.\n```\n\n### Or do it yourself:\n\nCreate `.github/workflows/deploy.yml`:\n\n```yaml\nname: Deploy to Cloudflare Workers\n\non:\n  push:\n    branches: [main]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: actions/setup-node@v4\n        with:\n          node-version: '22'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run tests\n        run: npm test\n\n      - name: Deploy\n        uses: cloudflare/wrangler-action@v3\n        with:\n          apiToken: ${{ secrets.CLOUDFLARE_API_TOKEN }}\n          accountId: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}\n```\n\nThis workflow triggers on every push to `main`, installs dependencies, runs your test suite, and deploys using the official Wrangler action.\n\n---\n\n## Step 5: Commit and Push\n\n### Ask your agent:\n\n```\nCommit all changes and push to main\n```\n\n### Or do it yourself:\n\n```bash\ngit add .\ngit commit -m \"Add deploy workflow\"\ngit push\n```\n\nGo to your repo on GitHub and click the **Actions** tab. You should see the workflow running. When it completes, your Worker is live at:\n\n`https://your-project.your-subdomain.workers.dev`\n\n---\n\n## Step 6: Deploy Updates\n\nAfter the initial setup, deploying changes is just a push:\n\n### Ask your agent:\n\n```\nCommit my changes and push to deploy\n```\n\n### Or do it yourself:\n\n```bash\ngit add .\ngit commit -m \"Describe your changes\"\ngit push\n```\n\nGitHub Actions picks up the push, runs tests, and deploys automatically.\n\n---\n\n## Quick Deploy (No Pipeline)\n\nFor quick iterations you can deploy directly from a terminal, but the GitHub Actions pipeline above is the recommended approach since your API token stays safely in GitHub secrets and never enters your terminal session.\n\n```bash\nexport CLOUDFLARE_API_TOKEN=\"your-token-here\"\nnpx wrangler deploy\n```\n\n---\n\n## Project Structure Checklist\n\nBefore deploying, make sure your project has these files:\n\n- `wrangler.toml` -- Wrangler configuration (name, compatibility date, bindings)\n- `package.json` -- Dependencies and scripts (npm test, npm run build)\n- `src/index.ts` -- Worker entry point\n- `tsconfig.json` -- TypeScript configuration\n- `.github/workflows/deploy.yml` -- CI/CD pipeline\n- `.gitignore` -- Exclude node_modules/, .wrangler/, .dev.vars\n\nA minimal `.gitignore` for Workers projects:\n\n```\nnode_modules/\ndist/\n.wrangler/\n.dev.vars\n```\n\n---\n\n## Working with KV, R2, and Durable Objects\n\nIf your project uses Cloudflare bindings, you need to create them before deploying.\n\n### Ask your agent:\n\n```\nCreate a KV namespace called MY_KV and an R2 bucket called my-bucket, then add the bindings to wrangler.toml\n```\n\n### Or do it yourself:\n\n**KV Namespace:**\n\n```bash\nnpx wrangler kv namespace create MY_KV\n```\n\nCopy the output ID into your `wrangler.toml`:\n\n```toml\n[[kv_namespaces]]\nbinding = \"MY_KV\"\nid = \"the-id-from-above\"\n```\n\n**R2 Bucket:**\n\n```bash\nnpx wrangler r2 bucket create my-bucket\n```\n\n```toml\n[[r2_buckets]]\nbinding = \"MY_BUCKET\"\nbucket_name = \"my-bucket\"\n```\n\n**Durable Objects** are declared in `wrangler.toml` and created automatically on deploy:\n\n```toml\n[[durable_objects.bindings]]\nname = \"MY_DO\"\nclass_name = \"MyDurableObject\"\n\n[[migrations]]\ntag = \"v1\"\nnew_classes = [\"MyDurableObject\"]\n```\n\n**Worker Secrets** (API keys, tokens that should not be in code):\n\n```bash\necho \"secret-value\" | npx wrangler secret put SECRET_NAME\n```\n\nSecrets are available in your Worker as `env.SECRET_NAME`.\n\n---\n\n## Environment Variables vs Secrets\n\n- **[vars] in wrangler.toml** -- stored in config file (committed), visible in code. Use for non-sensitive config like feature flags and URLs.\n- **wrangler secret put** -- stored in Cloudflare (encrypted), not visible in code. Use for API keys, tokens, and credentials.\n- **.dev.vars** -- local file (gitignored), only available during local development. Use for development secrets.\n\nExample `wrangler.toml` vars:\n\n```toml\n[vars]\nENVIRONMENT = \"production\"\nAPI_VERSION = \"v2\"\n```\n\n---\n\n## Tips\n\n**Test locally before deploying.** Use `npx wrangler dev` to run your Worker locally. It simulates the Cloudflare runtime, including KV and R2 bindings. Or ask your agent: \"Run this project locally with wrangler dev\".\n\n**Use branches for experiments.** You can add preview deploys on pull requests by extending the workflow to trigger on `pull_request` events.\n\n**Check deployment logs.** If a deploy fails, check the GitHub Actions log. Common issues:\n- Missing API token secret\n- Wrong account ID\n- Missing KV namespace or R2 bucket (create them first)\n- TypeScript errors (run `npm run build` locally to catch these)\n\n**Keep your token scoped.** The \"Edit Cloudflare Workers\" template grants only what is needed. Do not use a Global API Key -- it has full account access.\n"
  },
  {
    "key": "Examples/Advanced.md",
    "contentType": "text/markdown; charset=utf-8",
    "content": "# Public Blog on Cloudflare Workers\n\nBuild a public blog platform using Astro deployed to Cloudflare Workers. The blog has two\nfaces: a fast, public-facing site for readers and a protected management area for the author.\nView counts are tracked with Durable Objects so they survive redeploys and scale without a\ndatabase.\n\n## Development Approach\n\nTDD: write failing tests first, then implement. All tests pass before considering a section\ncomplete.\n\n## Stack and Constraints\n\nAstro with SSR via @astrojs/cloudflare adapter. Cloudflare Workers with Wrangler for local\ndev. Durable Objects for view counting (SQLite-backed). R2 bucket bound as BLOG_IMAGES for\nimage storage. KV namespace bound as BLOG_KV for posts. Cloudflare Access for management\narea auth. TypeScript strict mode. No client-side JS frameworks -- vanilla JS where\ninteractivity is needed.\n\nThe ViewCounter Durable Object class must be exported from the worker entry point. Astro's\nbuild output won't do this automatically -- you'll need a custom entry wrapper that re-exports\nboth the Astro worker and the DO class. Wrangler must use `new_sqlite_classes` (not\n`new_classes`) for DO migrations. Access Astro bindings via `Astro.locals.runtime.env`.\n\n## Public Blog Pages\n\nHome page (`/`) lists published posts sorted by date descending. Each entry shows title, date,\nexcerpt (first 160 chars), and thumbnail. Paginate at 10 posts per page with prev/next links\nvia `?page=N`. For performance, maintain a `posts:index` KV key with summary data instead of\nfetching every post individually -- update this index on every create/update/delete. Draft\nposts (published: false) must never appear on public pages.\n\nSingle post page (`/posts/[slug]`) fetches the post by slug from KV, renders markdown to HTML\n(use marked or remark), and shows title, author, date, tags, and an image gallery of\nassociated images (lazy-loaded). View counter is fetched server-side and incremented\nclient-side on page load. Unknown slugs return 404 with a friendly message.\n\nStatic about page (`/about`). Gallery page (`/gallery`) showing images across all posts.\n\nShared base layout with nav (Home, Gallery, About), footer, dark theme with CSS custom\nproperties. Responsive: single column below 768px, two-column grid above. Nav highlights\ncurrent page with `aria-current=\"page\"`. Home page renders with SSR -- no client-side JS\nrequired for content.\n\n## View Counter (Durable Objects)\n\nViewCounter DO class with a simple counter stored via `this.ctx.storage.get(\"count\")`.\nGET returns `{ slug, count }`, POST increments by 1 and returns the same shape. Each post\ngets its own isolated DO instance via `idFromName(slug)`.\n\nWorker API: `GET /api/views/:slug` and `POST /api/views/:slug` proxy to the DO stub.\nA never-viewed slug returns `{ slug, count: 0 }`. Counters persist across redeploys.\nConcurrent increments must not be lost -- 20 simultaneous POSTs must result in count 20.\n\n## Image Upload and R2 Storage\n\n`POST /api/upload` accepts multipart with an \"image\" field and a \"slug\" field to associate\nthe image with a post. Allowed types: JPEG, PNG, WebP, GIF. Max 10MB (reject with 413).\nNon-image types rejected with 400. Stored in R2 with correct content-type metadata. Returns\n`{ url, key, size, contentType }`.\n\n`GET /images/[...key]` serves images from R2 with immutable cache headers\n(`Cache-Control: public, max-age=31536000, immutable`). 404 if not found.\n\nPosts include an `images: string[]` field (R2 keys). After upload, the key is appended to\nthe post's images array in KV. Deleting a post must also delete its images from R2.\n\n## Protected Management Area\n\nCloudflare Access protects `/admin/*`, `/api/posts`, and `/api/upload`. Middleware reads the\n`CF_Authorization` cookie, verifies the JWT signature, expiration, and audience claim against\nthe Access JWKS endpoint, and extracts the user email for author attribution. Invalid or\nmissing JWT returns 401 for API routes and redirects to Access login for pages. Team domain\nand audience tag configured via environment variables.\n\nAdmin pages (server-rendered): dashboard at `/admin` (post count, total views, recent posts),\npost list at `/admin/posts` with edit/delete, create form at `/admin/posts/new`, edit form at\n`/admin/posts/[slug]`, and image upload at `/admin/upload` with drag-and-drop.\n\nCreate/edit form has title, slug (auto-generated from title, editable), content (textarea),\ntags (comma-separated), published checkbox, associated images with drag-to-upload, and a\nmarkdown preview panel.\n\nPost CRUD API: `GET /api/posts` (list, admin sees drafts), `GET /api/posts/:slug`,\n`POST /api/posts` (create), `PUT /api/posts/:slug` (update), `DELETE /api/posts/:slug`\n(cascades to R2 images). All mutations update the `posts:index` KV key.\n\nPost schema in KV (key `post:{slug}`): slug, title, content (raw markdown), excerpt\n(auto-generated, first 160 chars stripped of markdown), tags[], author (email from JWT),\nimages[] (R2 keys), published (boolean), publishedAt (ISO 8601, set on first publish, never\nchanged after), updatedAt, createdAt.\n\nSlug generation: lowercase, replace non-alphanumeric with hyphens, collapse multiples, trim\nedges. \"My First Post!\" becomes \"my-first-post\". \"Hello, World! #1\" becomes \"hello-world-1\".\n\nEditing a post preserves its original publishedAt. Deleting cascades to R2 images and updates\nposts:index.\n\n## Navigation and SEO\n\nResponsive nav: horizontal on desktop, hamburger on mobile (vanilla JS toggle). Active link\nvia `aria-current=\"page\"`. Skip-to-content link for accessibility.\n\nEvery page gets a unique `<title>` and `<meta name=\"description\">`. Post pages get Open Graph\ntags (og:title, og:description, og:image using the first post image or a fallback). Canonical\nURLs on all pages. RSS feed at `/rss.xml` (published posts only, valid XML). Sitemap at\n`/sitemap.xml` covering `/`, `/about`, `/gallery`, and all published post URLs.\n"
  },
  {
    "key": "Examples/Expert.md",
    "contentType": "text/markdown; charset=utf-8",
    "content": "# Ephemeral Cloud Development Environment\n\nBuild a browser-based cloud IDE on Cloudflare. Users get isolated Linux containers\nwith browser-native terminals, persistent file storage via R2, and a management\ndashboard. The system supports multiple AI coding agents (Claude, Codex, Gemini, or\nplain Bash), multiple terminal tabs per session with tiling layouts, and a setup\nwizard for first-time configuration. Expect a full day of work.\n\n## Development Approach\n\nTDD: write failing tests first, then implement. All tests pass before considering a\nphase complete. This project is too large for a single pass -- work through the\nphases in order, each producing a testable increment.\n\n## Architecture Overview\n\nThe request flow is: Browser to Cloudflare Worker (Hono router) to Durable Object\nto Container, with KV for metadata and R2 for file storage.\n\nThree code paths exist in the Worker entry point. First, WebSocket requests matching\n`/api/terminal/:id/ws` with an `Upgrade: websocket` header bypass Hono entirely --\nauth is performed manually by extracting the user from the Cloudflare Access JWT and\nvalidating the session in KV, then the WebSocket is proxied to the container. This\nbypass is required because Hono cannot handle WebSocket upgrade requests on Cloudflare\nWorkers. Second, requests to `/api/*`, `/public/*`, and `/health` go through the Hono\nmiddleware chain (request tracing, CORS, body size limits, error handler, auth, route\nhandlers). Third, everything else serves the SPA frontend from the ASSETS binding\nwith `not_found_handling = \"single-page-application\"`, but control-plane paths must\nbe declared in `run_worker_first` so they execute Worker logic instead of being\nswallowed by the SPA fallback.\n\nContainer lifecycle: the Worker calls `getContainer(env.CONTAINER, containerId)` where\n`containerId = bucketName-sessionId`. It sends `_internal/setBucketName` to the DO with\nR2 credentials. The container image starts, `onStart()` fires, and an activity poll\nalarm is scheduled at a 5-minute interval. The alarm checks an `/activity` endpoint on\nthe terminal server inside the container -- if there are no active WebSocket connections\nand no PTY output for 5 minutes, the container is destroyed. The DO's `destroy()`\noverride sets a `_destroyed` flag in storage, clears the alarm, then calls\n`super.destroy()`. If a stale alarm fires after destruction, it reads the `_destroyed`\nflag from storage before calling any Container base class methods -- this prevents\nzombie resurrection, because `getState()` on a destroyed container would wake it.\n\nKey invariants: one container per session (not per user). Container ID is\n`{bucketName}-{sessionId}` (compound key). Terminal ID is `{sessionId}-{terminalId}`\nwhere terminalId ranges from 1 to 6. All containers for the same user sync to the same\nR2 bucket. Home directory persists across sessions via R2 bisync. Never use\n`idFromName()` to check DO existence (it creates the DO) -- only `idFromString(hexId)`\nreferences existing DOs safely.\n\n## Stack and Constraints\n\nCloudflare Workers with Hono router. TypeScript strict mode. Vitest with\n`@cloudflare/vitest-pool-workers` for backend tests (tests run in Workers runtime).\nSolidJS with Vite for the frontend. xterm.js for terminal emulation. CSS with custom\nproperties for theming (no CSS-in-JS, all external CSS files). Zod for runtime\nvalidation on both backend (request bodies) and frontend (API responses). The container\nimage is Alpine-based with Node.js, and the terminal server inside the container is\nplain JavaScript (no TypeScript, no bundler).\n\nThe Durable Object class name must be lowercase `container` to match wrangler.toml\nmigrations. Renaming would require a destructive migration. The wrangler.toml\n`[[migrations]]` entry uses `new_sqlite_classes` (not `new_classes`). The DO extends\n`Container` from `@cloudflare/containers` with `defaultPort = 8080` and\n`sleepAfter = '24h'` (activity polling handles hibernation, not the platform default).\nThe `envVars` property must be set as a plain property assignment, not as a getter --\nCloudflare Containers reads it at `start()` time.\n\n## Worker Entry Point and Security\n\nThe Worker exports a custom `fetch` handler. It checks for WebSocket upgrade first,\nthen routes API/public/health paths through Hono, then handles SPA serving with setup\nand onboarding redirects.\n\nIf `setup:complete` is not in KV, non-setup pages redirect 302 to `/setup`. After\nsetup, the root path (`/`) redirects to `/app/` in default mode. When\n`ONBOARDING_LANDING_PAGE` is set to `active`, authenticated users at `/` redirect to\n`/app/`, while unauthenticated users see the SPA which renders a public waitlist\nlanding page with Turnstile bot protection.\n\nSecurity headers on every response: `Strict-Transport-Security: max-age=63072000;\nincludeSubDomains; preload`, `X-Content-Type-Options: nosniff`, `X-Frame-Options: DENY`,\n`Referrer-Policy: strict-origin-when-cross-origin`, `Permissions-Policy: camera=(),\nmicrophone=(), geolocation=()`. CSP on SPA responses includes `'self'`, `'unsafe-inline'`\nfor styles, Google Fonts origins, Gravatar for images, `wss:` for WebSocket connections,\nand Turnstile challenge origins for the onboarding page.\n\nBody size limit of 64KB on `/api/*` routes, except storage routes which define their own\nlimits (10MB for simple upload, 100MB for multipart parts).\n\n## Auth Chain and User Management\n\nCloudflare Access intercepts at the edge and sets the `cf-access-jwt-assertion` cookie\nand `cf-access-authenticated-user-email` header. The auth flow supports three methods:\nJWT verification against the Access JWKS endpoint (primary, when `auth_domain` and\n`access_aud` are stored in KV), trusted email header fallback (pre-setup only, before\nJWT config exists), and service token authentication via `CF-Access-Client-Id` header\n(for API/CLI clients). In DEV_MODE, a test user is returned when no Access headers are\npresent.\n\n`getUserFromRequest()` extracts the user identity. `resolveUserFromKV()` checks the\n`user:{email}` KV key and resolves the role (defaults to `'user'` for backward\ncompatibility). `authenticateRequest()` combines both, throwing `AuthError` if not\nauthenticated and `ForbiddenError` if the user is not in the allowlist. Email addresses\nare normalized (trimmed, lowercased) before every KV lookup, role resolution, and bucket\nname derivation.\n\nThe auth middleware sets `user` and `bucketName` on the Hono context. A separate\n`requireAdmin` middleware checks `user.role === 'admin'`. The WebSocket upgrade path\nduplicates auth logic by calling `authenticateRequest()` directly -- dual auth paths are\nunavoidable since WebSocket bypasses Hono.\n\nKV schema for users: key `user:{email}`, value\n`{ addedBy: string, addedAt: string, role: 'admin' | 'user' }`.\n\nPer-user bucket naming: `getBucketName(email, workerName)` produces a sanitized,\ndeterministic string like `codeflare-user-example-com`, max 63 chars.\n\nRate limiting uses KV storage with per-user keys (bucket name from auth, IP fallback).\nAn in-memory Map serves as fallback when KV is unreachable. Rate-limited responses\ninclude `X-RateLimit-Limit` and `X-RateLimit-Remaining` headers.\n\nUser management routes: `GET /api/users` lists allowed users (admin only).\n`POST /api/users` adds a user with email and optional role (admin only, rate-limited at\n20/min). `DELETE /api/users/:email` removes a user, destroys all their containers,\ndeletes their sessions from KV, attempts to delete their R2 bucket, and syncs the\nCloudflare Access policy. Users cannot delete themselves.\n\nError hierarchy: `AppError` base class with `code`, `statusCode`, `message`,\n`userMessage`, and a `toJSON()` that returns `{ error, code }`. Subclasses:\n`AuthError` (401), `ForbiddenError` (403), `ValidationError` (400), `NotFoundError` (404),\n`ContainerError` (500), `RateLimitError` (429), `CircuitBreakerOpenError` (503), and\n`SetupError` (400, custom `toJSON` with step progress array).\n\n## Session Management\n\nA session is a logical unit tying a user to a container, stored in KV with key\n`session:{bucketName}:{sessionId}`. The session object contains `id` (24-char lowercase\nhex, 96 bits of entropy), `name` (sanitized to `[a-zA-Z0-9 #_-]`), `userId` (bucket\nname), `createdAt` and `lastAccessedAt` (ISO timestamps), `status` (`'stopped'` or\n`'running'`), `lastStatusCheck` (epoch ms for stale detection), `agentType` (one of\n`'claude-unleashed'`, `'claude-code'`, `'codex'`, `'gemini'`, `'bash'`), and `tabConfig`\n(array of `{ id: \"1\"-\"6\", command: string, label: string }`).\n\nSession routes: `GET /api/sessions` lists user sessions sorted by `lastAccessedAt`\ndescending. `POST /api/sessions` creates a session (rate-limited at 10/min, validates\nwith Zod). `GET /api/sessions/:id` gets a session. `PATCH /api/sessions/:id` updates\nname or tab config. `DELETE /api/sessions/:id` destroys the container first (if\ndestruction fails, KV is kept so the user can retry), then deletes from KV.\n`POST /api/sessions/:id/touch` updates `lastAccessedAt`.\n`POST /api/sessions/:id/stop` sets KV status to `'stopped'` and calls\n`container.destroy()`. `GET /api/sessions/:id/status` returns session and container\nstatus -- if KV says `'stopped'`, the container probe is skipped to avoid waking the DO.\n`GET /api/sessions/batch-status` returns status for all sessions using\n`Promise.allSettled` so one failure does not block others. Sessions marked `'stopped'` in\nKV are trusted unless stale (older than 5 minutes).\n\nThe start flow: validate session in KV, create R2 bucket if needed via Cloudflare API,\nget container stub, POST `_internal/setBucketName` with R2 credentials and tab config,\nupdate session status in KV. The container starts asynchronously and the frontend polls\n`/api/container/startup-status` for progress.\n\n## Container Durable Object\n\nThe DO class extends `Container<Env>` with `defaultPort = 8080` and `sleepAfter = '24h'`.\nThe constructor runs `blockConcurrencyWhile` to check for the `_destroyed` flag (zombie\ndetection), load `bucketName` from storage, and resolve R2 config via a three-tier\nfallback: environment variables first, KV keys second, Cloudflare API auto-resolution\nthird (with KV caching for subsequent calls).\n\n`setBucketName()` stores the bucket name, R2 credentials, workspace sync preference, and\ntab config in DO storage, then calls `updateEnvVars()` which sets the `envVars` property\nwith `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `R2_ACCESS_KEY_ID`,\n`R2_SECRET_ACCESS_KEY`, `R2_ACCOUNT_ID`, `R2_BUCKET_NAME`, `R2_ENDPOINT`,\n`WORKSPACE_SYNC_ENABLED`, `SYNC_MODE`, `TERMINAL_PORT`, and optionally `TAB_CONFIG` as\nJSON. The `_internal/setBucketName` endpoint is idempotent -- once set, subsequent calls\nreturn 409.\n\nInternal route dispatch uses a Map keyed by `\"METHOD:path\"` for `_internal/setBucketName`\n(POST), `_internal/getBucketName` (GET), and `_internal/debugEnvVars` (GET, DEV_MODE\nonly). The `fetch()` override checks this map before falling through to\n`super.fetch()`.\n\n`onStart()` schedules the activity poll alarm. The alarm handler checks in strict order:\ndestroyed state (storage read only, no Container methods), orphan state (no bucket name),\ncontainer stopped state (via `getState()`), then idle timeout (via `/activity` endpoint\nwith 3 retries and 2-second delay between attempts). Idle means no active connections AND\nthe shortest idle duration across PTY output and WebSocket activity exceeds 5 minutes.\n\n`cleanupAndDestroy()` records shutdown info, sets the `_destroyed` flag, clears the\nalarm, and calls `destroy()`. The `destroy()` override clears the alarm, deletes\noperational storage keys (`bucketName`, `workspaceSyncEnabled`, `tabConfig`), but keeps\nthe `_destroyed` flag so stale alarms can detect zombie state.\n\nContainer routes served through Hono (with auth middleware): `POST /api/container/start`\n(rate-limited at 5/min), `POST /api/container/destroy`, `GET /api/container/health`,\n`GET /api/container/startup-status` (polling endpoint with 6 stages: stopped, starting,\nsyncing, verifying, mounting, ready), `GET /api/container/state` (DEV_MODE),\n`GET /api/container/debug` (DEV_MODE). A circuit breaker wraps container fetch calls with\n5-failure threshold, 30-second reset timeout, used for both health checks and session\nqueries.\n\n## Terminal Server\n\nThe terminal server runs inside the container as plain JavaScript on port 8080. It uses\n`ws` for WebSocket and `node-pty` for PTY sessions, plus `@xterm/headless` with\n`@xterm/addon-serialize` for capturing terminal state for reconnection.\n\nEndpoints: `WS /terminal?session={id}` connects to a terminal session.\n`GET /health` returns `{ status, activeSessions, syncStatus, prewarmReady, cpu, mem, hdd }`\nwhere CPU is load average percentage, memory is used/total in GB, and disk is parsed from\n`df` output (cached for 30 seconds). `GET /sessions` lists active PTY sessions.\n`GET /activity` returns `{ hasActiveConnections, lastPtyOutputMs, lastWsActivityMs }` for\nthe DO's hibernation decisions. `POST /_internal/setBucketName` stores R2 config.\n\nEach PTY session spawns `bash -l` (login shell, so `.bashrc` runs and auto-starts the\nconfigured agent) with `xterm-256color` and truecolor support, in the\n`/home/user/workspace` directory. Maximum 20 sessions per container. The terminal ID\nenvironment variable `TERMINAL_ID` is set per PTY (1-6).\n\nWebSocket protocol: client sends terminal input as raw text. Server sends terminal output\nas raw text. JSON control messages are used for resize (`{ type: \"resize\", cols, rows }`),\nping/pong (`{ type: \"ping\" }` / `{ type: \"pong\" }`), session restore\n(`{ type: \"restore\", state: \"...\" }`), and process name reporting\n(`{ type: \"process-name\", processName: \"...\" }`). On reconnect, the server serializes\nthe headless terminal state and sends it as a restore message. The client resets the\nterminal, writes the restored state, and forces a full refresh.\n\nPTY pre-warming: on server startup, a `prewarm-1` session is created for Tab 1. Readiness\nis detected via output quiescence (2 seconds of silence after output), with a 20-second\nhard timeout fallback. When the first real WebSocket connects for Tab 1, the pre-warmed\nsession is adopted by re-keying it (zero-copy handoff, no PTY restart). Orphan safety:\nthe pre-warmed session is killed after 2 minutes if never adopted. Pre-warm sessions are\nexcluded from the max sessions cap.\n\nProcess name detection: the server polls the PTY foreground process name and sends\n`process-name` control messages to the client when it changes. When the raw process name\nis generic (like `node`), the server falls back to the configured command from\n`TAB_CONFIG`.\n\n## SolidJS Frontend\n\nStack: SolidJS with reactive stores, xterm.js for terminal emulation, Vite for bundling,\nVitest with jsdom and SolidJS Testing Library for tests.\n\nRoute structure: `/` renders the onboarding landing page (lazy-loaded). `/setup` renders\nthe setup wizard. `/*` passes through a setup guard that checks `/api/setup/status` and\nredirects to `/setup` if needed, then renders `AppContent` which fetches user info and\nrenders the Layout.\n\nThe design system uses a dark theme with zinc-based backgrounds (`#09090b` base), HSL-based\naccent color (configurable via `--accent-hue` CSS custom property, with a color picker in\nsettings), and 100+ CSS custom properties in `design-tokens.css`. Typography uses Inter\nfor UI and JetBrains Mono for code (loaded from Google Fonts). All components use external\nCSS files. The component library includes Button (primary, secondary, ghost, danger\nvariants) and Input (with icon support).\n\nSolidJS store pattern: module-level singletons using `createStore` + `produce`. Export\nstate getter object and action functions. Map objects live outside the reactive store for\nWebSocket references, Terminal instances, and FitAddon references -- SolidJS stores do\nnot track Map mutations.\n\n### Dashboard\n\nThe Layout component manages two views: dashboard and terminal. When a session is\nselected and running, the view transitions to terminal. The dashboard shows a session\nlist with cards, stat cards, and a tips rotator. The tips rotator displays context-aware\ntips (mobile tips on touch devices, desktop tips on pointer devices, general on all),\nauto-rotates every 15 seconds, and displays a random developer quote beneath each tip.\n\nSession cards show name, status badge, agent type icon, and relative time. Running\nsessions show metrics (CPU, memory, disk from container health). Action buttons for\nstop and delete are accessible from a context menu (long-press on mobile, right-click on\ndesktop) and a dropdown menu on the card. Delete is always available, including during\ninitialization, to handle stuck sessions. Stop is available during initialization to\ncancel stuck startups.\n\n### Create Session Dialog\n\nA dialog for creating new sessions with name input, agent type selector (icons for each\nagent: Claude Unleashed, Claude Code, Codex, Gemini, Bash), and optional tab\nconfiguration from saved presets. The selected agent type and preset persist in user\npreferences across sessions.\n\n### Session Presets and Preferences\n\nUsers can save up to 3 tab configuration presets. Each preset stores a name and an array\nof tab configs (`{ id, command, label }`). Presets are stored in KV under\n`presets:{bucketName}`. Routes: `GET /api/presets`, `POST /api/presets`,\n`DELETE /api/presets/:id`.\n\nUser preferences persist last agent type, last preset ID, and workspace sync toggle.\nStored in KV under `user-prefs:{bucketName}`. Routes: `GET /api/preferences`,\n`PATCH /api/preferences` (merge semantics).\n\n### Terminal Component\n\nWraps xterm.js with WebSocket connection management. Keyboard handling: Ctrl+C copies if\na selection exists, otherwise sends SIGINT. Ctrl+V pastes from clipboard. FitAddon\nhandles terminal resizing. On reconnect, the component waits for a restore control\nmessage from the server, resets the terminal, writes the restored state, scrolls to\nbottom, and forces a full refresh.\n\nURL link detection in the terminal joins wrapped lines (both xterm `isWrapped` chains and\na heuristic for application-inserted newlines like ink-based TUIs) to reconstruct full\nURLs that span multiple terminal rows.\n\nMobile support: virtual keyboard detection via `visualViewport` API, swipe gestures for\ncursor movement (left/right) and command history (up/down), floating terminal buttons\nthat reposition when the keyboard opens. The `enableVirtualKeyboardOverlay` and\n`disableVirtualKeyboardOverlay` functions manage the `virtualKeyboard.overlaysContent`\nAPI for proper keyboard handling.\n\n### Terminal Tabs\n\nTab bar with icons per tab (icons update dynamically based on the foreground process\nname detected by the server). Tab 1 is fixed in position. Tabs 2-6 are reorderable via\ndrag-and-drop. Active tab indicator highlights the current tab. Tab order persists to\nlocalStorage.\n\n### Tiling\n\nA tiling button appears when 2 or more tabs exist. Layouts: tabbed (default), 2-split,\n3-split, 4-grid. Each layout requires a minimum tab count (2, 3, 4 respectively). Layout\nchoice persists to localStorage. After layout changes, terminals refit with a delay to\nallow CSS transitions to settle, then send resize events to the PTY and force a full\nterminal refresh to fix garbling in TUI apps like htop.\n\n### Init Progress\n\nA modal showing container startup stages: creating, starting, syncing, verifying,\nmounting (PTY pre-warming -- \"Preparing terminal\"), and ready. Each stage has an icon,\na label, and per-stage timing. The total time counter uses the `startedAt` timestamp from\nsession initiation, not the first poll response. System metrics (CPU, memory, disk) are\nshown during startup once available from the health endpoint.\n\n### Settings Panel\n\nA slide-out panel with user management section (add/remove users, admin-only visibility),\naccent color picker, workspace sync toggle, and terminal button label toggle. Mutual\nexclusion with the storage panel -- opening one closes the other.\n\n### Storage Browser\n\nR2 file browser with breadcrumb navigation, starting at the `workspace/` prefix. Toolbar\nwith upload, download, delete, move, and selection mode buttons. Upload supports\ndrag-and-drop and chunked multipart for large files. Files can be previewed (text and\nimages) in a slide-out panel. Selection mode allows batch operations. Storage stats show\ntotal files, folders, and size.\n\nDesktop layout: 400px slide-in drawer. Mobile layout: bottom sheet. The storage browser\nreads directly from R2 via the Worker API -- it does not trigger container-side sync.\nContainer sync is handled by the 60-second bisync daemon independently.\n\n### Onboarding Landing Page\n\nWhen `ONBOARDING_LANDING_PAGE` is active, unauthenticated visitors at `/` see a public\nwaitlist page with email input, Turnstile bot protection, and a submit button. The page\nfetches config from `GET /public/onboarding-config` (returns Turnstile site key). The\nwaitlist submission (`POST /public/waitlist`, rate-limited at 5/min) verifies the\nTurnstile token, then sends an email to all admin users via Resend API with the\nsubmitted email, timestamp, and IP. Authenticated users at `/` skip the landing page\nand redirect to `/app/`.\n\nThe SPA renders the `OnboardingLanding` component which includes animated visual\nelements (`SplashCursor`, `KittScanner`), dynamically loads the Turnstile script, and\nhandles form submission with loading and success/error states.\n\n### API Client\n\n`fetchApi<T>(path, options, schema?)` with optional Zod validation. Throws `ApiError` on\nnon-OK responses. `getTerminalWebSocketUrl(sessionId, terminalId)` produces the WebSocket\nURL with compound terminal ID format. All API response types are validated against Zod\nschemas defined in `lib/schemas.ts`, with TypeScript types derived from schemas via\n`z.infer`.\n\n### Stores\n\n`terminal.ts`: WebSocket connections with compound key management\n(`sessionId:terminalId`). Maps for connections, terminals, fitAddons, inputDisposables,\nand reconnection attempts live outside the reactive store. Connection retries: 45\nattempts with 1.5-second delay for initial connect, 5 reconnection attempts with\n2-second delay for dropped connections. Application-level ping every 25 seconds keeps\nidle connections alive. Watchdog closes WebSocket if no data received for 45 seconds.\nThe `inputDisposable` must be stored outside `connect()` and disposed before creating a\nnew handler on reconnect to prevent character doubling.\n\n`session.ts`: session CRUD, metrics polling (5-second interval for running sessions),\nstartup status polling (1.5-second interval), terminal tab management (add, remove,\nreorder, rename), and integration with presets and preferences stores.\n\n`setup.ts`: wizard state and validation for the 3-step setup flow.\n\n`storage.ts`: R2 browser state (browse, upload with progress tracking, download,\ndelete, move, preview, stats), with selection mode and pagination support.\n\n`tiling.ts`: layout state management with session store access via lazy registration\npattern (avoids circular imports). Exports helpers for layout compatibility checks and\nbest-layout selection.\n\n## Setup Wizard\n\nFirst-time visitors hit an edge-level redirect: `GET /` returns 302 to `/setup` when\n`setup:complete` is not in KV.\n\nBackend routes: `GET /api/setup/status` returns `{ configured, customDomain }`.\n`GET /api/setup/detect-token` verifies `CLOUDFLARE_API_TOKEN` against the Cloudflare\nAPI and returns account info. `GET /api/setup/prefill` reads existing Access group\nmembership for redeploy prefill. `POST /api/setup/configure` runs the full\nconfiguration flow. All endpoints are rate-limited. Before setup is complete, these\nendpoints are publicly accessible (bootstrap chicken-and-egg). After setup, they\nrequire admin auth.\n\nThe configure flow accepts `{ customDomain, allowedUsers, adminUsers, allowedOrigins? }`.\nSteps: get account ID from API, derive R2 S3 credentials (access key ID from\n`/user/tokens/verify`, secret key from SHA-256 hash of the token value), set worker\nsecrets (R2 credentials), store users in KV with roles (removing stale users not in the\nnew list), create DNS CNAME record (upsert pattern: check if exists, PUT to update or\nPOST to create), create Cloudflare Access application with five destinations (`/app`,\n`/app/*`, `/api/*`, `/setup`, `/setup/*`) and per-worker Access groups\n(`{workerName}-admins`, `{workerName}-users`), optionally configure Turnstile for\nonboarding mode, store custom domain and combined allowed origins in KV, and finally\nwrite `setup:complete = \"true\"` to KV as the last step for atomicity. If any\nprerequisite fails, the system is not marked as configured.\n\nA KV-based lock with 300-second TTL prevents concurrent configure runs. Stale locks\nolder than 60 seconds are overridden. After configuration completes, all in-memory caches\n(CORS origins, auth config, JWKS) are reset.\n\nFrontend: `SetupWizard.tsx` orchestrates three steps. `WelcomeStep.tsx` calls\n`detect-token` on mount and shows token status with account info. `ConfigureStep.tsx`\nprovides a form for custom domain, allowed users, admin users, and optional CORS origins.\n`ProgressStep.tsx` shows step-by-step configuration progress with status indicators per\nstep.\n\n## R2 Storage and File Sync\n\nR2 storage serves two purposes: the file browser in the UI, and container-side sync\nvia rclone.\n\nStorage API routes: `GET /api/storage/browse` lists objects and prefixes.\n`GET /api/storage/download` downloads a file. `POST /api/storage/upload` handles single\nor multipart upload (with `/upload/initiate`, `/upload/part`, `/upload/complete` for\nchunked multipart). `POST /api/storage/delete` deletes objects.\n`POST /api/storage/move` renames/moves objects. `GET /api/storage/stats` returns total\nfiles, folders, and size. `GET /api/storage/preview` returns file content for text files\nand signed URLs for images. `POST /api/storage/seed/getting-started` creates starter\ndocumentation in R2 (tutorials, getting started guide) -- called automatically when a\nuser's bucket is first created.\n\nThe R2 client uses the S3-compatible API via `@aws-sdk/client-s3` for storage operations.\nR2 config resolution follows a three-tier fallback: environment variables, KV keys\n(`setup:account_id`, `setup:r2_endpoint`), and self-healing from the Cloudflare API token\n(resolves account ID, caches in KV for subsequent calls).\n\nPer-user buckets are created dynamically via the Cloudflare API on first container start.\n`createBucketIfNotExists` handles the \"already exists\" race condition gracefully.\n\nContainer sync uses rclone in `entrypoint.sh`. Initial sync is one-way R2-to-local\n(blocking, restores user data). Then `rclone bisync --resync` establishes a baseline, and\na 60-second daemon runs bisync in the background. On SIGTERM, a final bisync runs before\nthe container exits. Sync modes are controlled by `SYNC_MODE`: `none` (default, settings\nand config only), `full` (entire workspace minus `node_modules/`), and `metadata`\n(`CLAUDE.md` + `.claude/` per repo only). Exclusions always include `node_modules/`,\n`.npm/`, `.cache/rclone/`, `.config/rclone/`, `.claude/debug/`, `.claude/plugins/cache/`.\nAll rclone commands use `--filter` flags, never `--include`/`--exclude` together. Conflict\nresolution: newest file wins (`--conflict-resolve newer`), with automatic `--resync` on\nbisync failure.\n\n## Terminal WebSocket Proxy\n\nThe Worker proxies WebSocket connections between the browser and the container. This path\nbypasses Hono entirely for performance.\n\n`validateWebSocketRoute()` checks whether the path matches `/api/terminal/:id/ws` with an\n`Upgrade: websocket` header. Returns null if not a WebSocket route (falls through to\nHono). `handleWebSocketUpgrade()` extracts the compound terminal ID, validates the base\nsession ID format (8-24 lowercase alphanumeric), authenticates the user, validates Origin\nheader against the allowed origins list (browser clients require Origin; CLI clients like\nwscat are intentionally allowed without it), rate-limits WebSocket connections at 30/min\nper user (fail-open on KV errors), validates the session exists in KV, gets the container\nstub, and forwards the WebSocket upgrade with the full compound ID and session name as\nquery parameters.\n\nFrontend WebSocket management: compound keys `sessionId:terminalId` for state tracking.\nWebSocket URL: `/api/terminal/{sessionId}-{terminalId}/ws`. Maps for sockets, terminals,\nand fitAddons live outside the reactive store. On successful connection, an initial resize\nis sent to sync PTY dimensions with xterm.js (prevents garbled text from dimension\nmismatch). Reconnection with exponential backoff and the `inputDisposable` pattern\nprevents character doubling.\n\nThe terminal status route `GET /api/terminal/:sessionId/status` is served through normal\nHono middleware (with auth) and checks container health plus active PTY sessions.\n\n## Container Image\n\nAlpine-based multi-stage Dockerfile. Builder stage compiles `node-pty` native addon.\nRuntime stage installs: rclone, git, GitHub CLI, vim, nano, neovim, curl, openssh-client,\njq, ripgrep, fd, tree, htop, tmux, fzf, zoxide, yazi (from GitHub release), lazygit\n(from GitHub release), bat, and p7zip. AI agents installed globally: `claude-unleashed`\n(from GitHub, pre-patched at build time with V8 compile cache seeded), `@anthropic-ai/claude-code`,\n`@openai/codex`, `@google/gemini-cli`. All agent installs fail gracefully since they are\noptional.\n\nA browser shim (`/usr/local/bin/open-url`) exits with code 1 so Claude Code falls back\nto displaying auth URLs as text in its TUI -- the xterm.js WebLinksAddon makes them\nclickable.\n\nEnvironment variables: `CLAUDE_UNLEASHED_SKIP_CONSENT=1`, `DISABLE_INSTALLATION_CHECKS=1`,\n`IS_SANDBOX=1`, `NODE_COMPILE_CACHE=/root/.cache/node-compile-cache`.\n\nThe entrypoint creates rclone config from R2 environment variables, runs initial sync,\nconfigures `.bashrc` tab autostart based on `TAB_CONFIG` (Tab 1 starts the selected\nagent, Tab 2 htop, Tab 3 yazi, Tabs 4-6 plain bash, with auto-restart loops), and\nstarts the terminal server on port 8080. SIGTERM handler runs a final bisync before\nexit. `STOPSIGNAL` is `SIGINT`.\n\nWorking directory: `/home/user/workspace`. Home directory: `/home/user`.\n\n## E2E Tests\n\nE2E tests verify the full system against a deployed worker. DEV_MODE is enabled in\nwrangler.toml to bypass Cloudflare Access during testing, with `ACCOUNT_SUBDOMAIN` env\nvar for the worker URL.\n\nAPI tests cover: user info, session list, session creation, full session lifecycle\n(create, start, verify running, stop, delete).\n\nUI tests use Puppeteer: layout loads with header and main area, session creation dialog\nworks, terminal connects and accepts input, settings panel opens and closes, setup wizard\ncompletes (uses test-only `POST /api/setup/reset-for-tests` and\n`POST /api/setup/restore-for-tests` endpoints gated behind DEV_MODE).\n\nTest cleanup: `afterAll` deletes all test sessions and restores the `setup:complete` flag.\n\n## Additional API Routes\n\n`GET /api/user` returns the authenticated user's email, role, `onboardingActive` flag,\nand `workerName`.\n\n`POST /api/admin/destroy-by-id` kills zombie containers by raw DO ID (admin auth\nrequired, body `{ doId: \"64-char-hex\" }`). This is the only route that uses\n`idFromString()` which safely references existing DOs without creating new ones.\n"
  },
  {
    "key": "Examples/Intermediate.md",
    "contentType": "text/markdown; charset=utf-8",
    "content": "# Build a Personal CV Website with Contact Form\n\nBuild and deploy a personal CV website on Cloudflare Workers with a Turnstile-protected\ncontact form. Hono for routing, vanilla HTML/CSS/JS, no frameworks.\n\n## Pages\n\n**Home / CV page** (`GET /`) -- Hero section with name, title, and short bio. Work experience\n(2-3 entries with company, role, dates, description). Skills grouped by category. Education\n(1-2 entries). Link to contact page. Use placeholder content -- the user will replace it later.\n\n**Contact page** (`GET /contact`) -- Form with name (required), email (required, validated),\nand message (required, min 10 chars). Cloudflare Turnstile widget for bot protection. Submit\nbutton with loading state. Success/error feedback shown inline after submission.\n\n**Contact form handler** (`POST /api/contact`) -- Validates all fields server-side. Verifies\nTurnstile token via Cloudflare's siteverify API. Stores valid submissions in Workers KV.\nReturns JSON: `{ success: true }` or `{ success: false, error: \"...\" }`.\n\n**Messages endpoint** (`GET /api/messages`) -- Returns all stored contact form submissions as\nJSON array, sorted by timestamp descending (newest first).\n\n**404 page** -- Styled \"Page Not Found\" for unknown routes.\n\n## Design\n\nResponsive from 320px to 1440px. Dark theme with a single accent color. System font stack --\nno external font loading. Semantic HTML (proper heading hierarchy, nav, main, section, footer).\nPrint stylesheet for the CV page that hides nav and contact link.\n\n## Technical Details\n\n- Turnstile secret key stored as a Worker secret (`TURNSTILE_SECRET_KEY`)\n- Turnstile site key embedded in the contact page HTML\n- KV namespace bound as `MESSAGES` for storing submissions\n- For local development, use Turnstile test keys:\n  - Site key: `1x00000000000000000000AA` (always passes)\n  - Secret key: `1x0000000000000000000000000000000AA` (always passes)\n\n## Development Approach\n\nTDD: write failing tests first, then implement. All tests pass before deployment.\n"
  },
  {
    "key": "Examples/Intro.md",
    "contentType": "text/markdown; charset=utf-8",
    "content": "# Examples\n\nThese are specifications. Each one describes a complete project -- requirements, constraints, tests, and acceptance criteria. Everything an AI agent needs to build it from scratch without asking you a single question.\n\n## How to Use\n\n1. Create a session, pick your agent\n2. Open Tab 1\n3. Tell it: **\"Plan implementation of the Advanced.md specification\"** (or whichever one you picked)\n4. Go through the plan with the agent -- you need to make some decisions in order to create an implementation plan\n5. Approve the implementation plan\n6. Go watch Game of Thrones again\n\nThe planning step is not optional. The spec tells the agent *what* to build -- the agent still needs to figure out *how*. During planning, the agent reads the spec, asks follow-up questions about scaffolding, file structure, dependency choices, and execution order, then produces a detailed implementation document -- a step-by-step blueprint covering every file, every function, every test. Once you review and approve it, the agent exits planning mode and executes against that document. This is where a specification becomes a working project.\n\nAfter planning, the agent writes failing tests, implements until they pass, and deploys to Cloudflare. You come back to a working project with a full test suite and plausible deniability about who actually wrote it.\n\nEach spec follows TDD -- tests first, then implementation. This isn't a style preference. It's the single most effective way to keep a coding agent on track.\n\nWhen the agent writes tests first, every subsequent `npm test` run injects your expectations back into its context. If it drifts off course -- wrong return type, missing validation, broken edge case -- the failing test tells it exactly what went wrong and what was expected. The agent course-corrects without you lifting a finger. Without tests, the agent has no feedback loop. It writes code, assumes it works, and moves on. By the time you notice something is wrong, it's three features deep into a broken foundation.\n\nTDD turns your spec into a live guardrail. The agent can't cheat. If it says it's done and the tests don't pass, it lied. Make it try again.\n\n## Difficulty Levels\n\n| Example | Time | What You Get |\n|---------|------|-------------|\n| [Simple](Simple.md) | ~15 min | Hello World Worker. The agent does all of it. You take the credit. |\n| [Intermediate](Intermediate.md) | ~30-45 min | CV website with Turnstile-protected contact form. Tell your recruiter you built it yourself. |\n| [Advanced](Advanced.md) | ~1-2 hours | Full blog with Durable Objects, R2 storage, and a CMS. The agent will complain less than an intern. |\n| [Expert](Expert.md) | ~1 day | You're rebuilding Codeflare itself. Bring coffee. |\n\nStart with Simple if this is your first session. Start with Expert if you have something to prove.\n\n## Writing Your Own Specs\n\nThese examples are meant to be a starting point. For your own projects, use your coding agent to develop a detailed specification *before* writing any code. Not a list of requirements -- a specification. The difference matters.\n\nA specification defines what the system does, what technology it uses, how components interact, what the data looks like, what edge cases exist, what the tests verify, and what acceptance looks like. It's specific enough that the agent can execute without asking you a single question. If the agent has to guess, the spec isn't done.\n\nTools like the `superpowers:brainstorming` skill or the `sequential-thinking` MCP server are built for this. Describe what you want to build, let the agent ask the right questions, and iterate until the spec is tight enough that implementation becomes mechanical. The more precise the spec, the less the agent improvises -- and improvisation is where things go sideways.\n"
  },
  {
    "key": "Examples/Simple.md",
    "contentType": "text/markdown; charset=utf-8",
    "content": "# Deploy a Hello World Worker\n\nBuild and deploy a Hello World Cloudflare Worker using the Hono framework. No external\ndependencies beyond what the scaffold provides.\n\n## Routes\n\n`GET /` returns plain text \"Hello World\" with status 200.\n\n`GET /api/info` returns JSON with three fields: `status` (\"ok\"), `timestamp` (valid ISO 8601),\nand `runtime` (\"cloudflare-workers\").\n\nAny other route returns plain text \"Not Found\" with status 404.\n\n## Development Approach\n\nTDD: write failing tests first, then implement. All tests pass before deployment.\n"
  }
];
